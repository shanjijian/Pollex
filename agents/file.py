"""
File Agent - æ–‡ä»¶æ™ºèƒ½ä½“
è´Ÿè´£æ–‡ä»¶è¯»å†™å’Œç›®å½•ç®¡ç†
"""
import json
from typing import Optional
from openai import AsyncOpenAI

from core.agent import BaseAgent, AgentRole, AgentResponse, Message
from tools.file import ReadFileTool, WriteFileTool, ListDirTool
from utils.log import get_logger
from config import config

logger = get_logger("agent")


FILE_AGENT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ–‡ä»¶ç®¡ç†æ™ºèƒ½ä½“ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ç†è§£ç”¨æˆ·çš„æ–‡ä»¶æ“ä½œéœ€æ±‚
2. æ‰§è¡Œæ–‡ä»¶è¯»å–ã€å†™å…¥å’Œç›®å½•æ“ä½œ
3. å®‰å…¨åœ°å¤„ç†æ–‡ä»¶ç³»ç»Ÿ

ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·ï¼š
- read_file: è¯»å–æ–‡ä»¶å†…å®¹
- write_file: å†™å…¥æ–‡ä»¶
- list_dir: åˆ—å‡ºç›®å½•å†…å®¹

è§„åˆ™ï¼š
- æ“ä½œå‰ç¡®è®¤è·¯å¾„æ­£ç¡®
- å†™å…¥å‰æé†’å¯èƒ½è¦†ç›–ç°æœ‰å†…å®¹
- ä¸æ“ä½œæ•æ„Ÿç³»ç»Ÿæ–‡ä»¶
- é‡åˆ°é”™è¯¯æ—¶ç»™å‡ºæ¸…æ™°çš„è¯´æ˜"""


class FileAgent(BaseAgent):
    """æ–‡ä»¶æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.read_tool = ReadFileTool()
        self.write_tool = WriteFileTool()
        self.list_tool = ListDirTool()
        super().__init__(
            name="FileAgent",
            role=AgentRole.FILE,
            system_prompt=FILE_AGENT_PROMPT,
            tools=[self.read_tool, self.write_tool, self.list_tool]
        )
        self.client: Optional[AsyncOpenAI] = None
    
    def _ensure_client(self):
        """ç¡®ä¿ OpenAI å®¢æˆ·ç«¯å·²åˆå§‹åŒ–"""
        if self.client is None:
            if config.llm_config is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨ init_config() åˆå§‹åŒ–é…ç½®")
            self.client = AsyncOpenAI(api_key=config.llm_config.api_key, base_url=config.llm_config.base_url)
    
    async def think(self, task: str) -> str:
        """åˆ†ææ–‡ä»¶æ“ä½œéœ€æ±‚"""
        self._ensure_client()
        
        self.add_message(Message(role="user", content=task))
        
        response = await self.client.chat.completions.create(
            model=config.llm_config.model,
            messages=self.get_messages_for_llm(),
            tools=self.get_tools_schema(),
            temperature=config.llm_config.temperature,
        )
        
        message = response.choices[0].message
        
        self.add_message(Message(
            role="assistant",
            content=message.content or "",
            tool_calls=[tc.model_dump() for tc in message.tool_calls] if message.tool_calls else None
        ))
        
        if message.tool_calls:
            return f"éœ€è¦æ‰§è¡Œæ–‡ä»¶æ“ä½œ: {len(message.tool_calls)} ä¸ª"
        
        return message.content or "æ— éœ€æ–‡ä»¶æ“ä½œ"
    
    async def act(self, plan: str) -> AgentResponse:
        """æ‰§è¡Œæ–‡ä»¶æ“ä½œ"""
        if not self.messages:
            return AgentResponse(success=False, content="", error="æ²¡æœ‰å¾…æ‰§è¡Œçš„æ“ä½œ")
        
        last_message = self.messages[-1]
        if not last_message.tool_calls:
            return AgentResponse(
                success=True,
                content=last_message.content,
                data=None
            )
        
        results = []
        for tool_call in last_message.tool_calls:
            func = tool_call.get("function", {})
            func_name = func.get("name")
            func_args = json.loads(func.get("arguments", "{}"))
            
            if func_name == "read_file":
                result = await self.read_tool.execute(**func_args)
            elif func_name == "write_file":
                result = await self.write_tool.execute(**func_args)
            elif func_name == "list_dir":
                result = await self.list_tool.execute(**func_args)
            else:
                continue
            
            results.append(result)
            self.add_message(Message(
                role="tool",
                content=str(result),
                tool_call_id=tool_call.get("id")
            ))
        
        all_success = all(r.success for r in results)
        content = "\n\n".join(str(r) for r in results)
        
        return AgentResponse(
            success=all_success,
            content=content,
            data=results
        )
    
    async def observe(self, result: AgentResponse) -> str:
        """æ€»ç»“æ–‡ä»¶æ“ä½œç»“æœ"""
        self._ensure_client()
        
        if not result.success:
            return f"æ“ä½œå¤±è´¥: {result.error}"
        
        self.add_message(Message(
            role="user",
            content=f"è¯·ç®€è¦è¯´æ˜å®Œæˆäº†ä»€ä¹ˆæ–‡ä»¶æ“ä½œã€‚ç»“æœ:\n{result.content[:2000]}"
        ))
        
        response = await self.client.chat.completions.create(
            model=config.llm_config.model,
            messages=self.get_messages_for_llm(),
            temperature=0.3,
            max_tokens=300
        )
        
        summary = response.choices[0].message.content
        self.add_message(Message(role="assistant", content=summary))
        
        return summary
    
    async def run(self, task: str) -> AgentResponse:
        """è¿è¡Œå®Œæ•´çš„æ–‡ä»¶æ“ä½œæµç¨‹"""
        self.clear_messages()
        
        plan = await self.think(task)
        result = await self.act(plan)
        
        if result.success:
            observation = await self.observe(result)
            result.content = f"{result.content}\n\nğŸ“ æ€»ç»“: {observation}"
        
        return result
