"""
Data Agent - æ•°æ®åˆ†ææ™ºèƒ½ä½“
è´Ÿè´£æ•°æ®å¤„ç†å’Œåˆ†æ
"""
import json
from typing import Optional
from openai import AsyncOpenAI

from core.agent import BaseAgent, AgentRole, AgentResponse, Message
from tools.code import ExecutePythonTool
from config import config
from utils.log import get_logger

logger = get_logger("agent")


DATA_AGENT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†ææ™ºèƒ½ä½“ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ç†è§£ç”¨æˆ·çš„æ•°æ®åˆ†æéœ€æ±‚
2. ä½¿ç”¨ Python è¿›è¡Œæ•°æ®å¤„ç†å’Œåˆ†æ
3. ç”Ÿæˆç»Ÿè®¡ç»“æœå’Œå¯è§†åŒ–

ä½ å¯ä»¥ä½¿ç”¨ execute_python å·¥å…·æ‰§è¡Œæ•°æ®åˆ†æä»£ç ã€‚

å¯ç”¨çš„åº“ï¼š
- pandas: æ•°æ®å¤„ç†
- numpy: æ•°å€¼è®¡ç®—
- matplotlib: æ•°æ®å¯è§†åŒ–
- json, csv: æ•°æ®æ ¼å¼å¤„ç†

è§„åˆ™ï¼š
- ä»£ç è¦é«˜æ•ˆã€å¯è¯»
- å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸æ•°æ®
- å¯è§†åŒ–å›¾è¡¨è¦æ¸…æ™°
- ç»™å‡ºåˆ†æç»“è®º"""


class DataAgent(BaseAgent):
    """æ•°æ®åˆ†ææ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.execute_tool = ExecutePythonTool()
        super().__init__(
            name="DataAgent",
            role=AgentRole.DATA,
            system_prompt=DATA_AGENT_PROMPT,
            tools=[self.execute_tool]
        )
        self.client: Optional[AsyncOpenAI] = None
    
    def _ensure_client(self):
        """ç¡®ä¿ OpenAI å®¢æˆ·ç«¯å·²åˆå§‹åŒ–"""
        if self.client is None:
            if config.llm_config is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨ init_config() åˆå§‹åŒ–é…ç½®")
            self.client = AsyncOpenAI(api_key=config.llm_config.api_key, base_url=config.llm_config.base_url)
    
    async def think(self, task: str) -> str:
        """åˆ†ææ•°æ®å¤„ç†éœ€æ±‚"""
        self._ensure_client()
        
        self.add_message(Message(role="user", content=task))
        
        response = await self.client.chat.completions.create(
            model=config.llm_config.model,
            messages=self.get_messages_for_llm(),
            tools=self.get_tools_schema(),
            temperature=config.llm_config.temperature,
        )
        
        message = response.choices[0].message
        
        self.add_message(Message(
            role="assistant",
            content=message.content or "",
            tool_calls=[tc.model_dump() for tc in message.tool_calls] if message.tool_calls else None
        ))
        
        if message.tool_calls:
            return f"éœ€è¦æ‰§è¡Œæ•°æ®åˆ†æ: {len(message.tool_calls)} ä¸ªæ“ä½œ"
        
        return message.content or "æ— éœ€æ•°æ®åˆ†æ"
    
    async def act(self, plan: str) -> AgentResponse:
        """æ‰§è¡Œæ•°æ®åˆ†æ"""
        if not self.messages:
            return AgentResponse(success=False, content="", error="æ²¡æœ‰å¾…æ‰§è¡Œçš„æ“ä½œ")
        
        last_message = self.messages[-1]
        if not last_message.tool_calls:
            return AgentResponse(
                success=True,
                content=last_message.content,
                data=None
            )
        
        results = []
        for tool_call in last_message.tool_calls:
            func = tool_call.get("function", {})
            func_name = func.get("name")
            func_args = json.loads(func.get("arguments", "{}"))
            
            if func_name == "execute_python":
                result = await self.execute_tool.execute(**func_args)
                results.append(result)
                
                self.add_message(Message(
                    role="tool",
                    content=str(result),
                    tool_call_id=tool_call.get("id")
                ))
        
        all_success = all(r.success for r in results)
        content = "\n\n".join(str(r) for r in results)
        
        return AgentResponse(
            success=all_success,
            content=content,
            data=results
        )
    
    async def observe(self, result: AgentResponse) -> str:
        """åˆ†ææ‰§è¡Œç»“æœï¼Œç»™å‡ºæ•°æ®æ´å¯Ÿ"""
        self._ensure_client()
        
        if not result.success:
            return f"åˆ†æå¤±è´¥: {result.error}"
        
        self.add_message(Message(
            role="user",
            content=f"è¯·æ ¹æ®æ•°æ®åˆ†æç»“æœï¼Œç»™å‡ºå…³é”®æ´å¯Ÿå’Œç»“è®ºã€‚åˆ†æç»“æœ:\n{result.content}"
        ))
        
        response = await self.client.chat.completions.create(
            model=config.llm_config.model,
            messages=self.get_messages_for_llm(),
            temperature=0.3,
            max_tokens=800
        )
        
        summary = response.choices[0].message.content
        self.add_message(Message(role="assistant", content=summary))
        
        return summary
    
    async def run(self, task: str) -> AgentResponse:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®åˆ†ææµç¨‹"""
        self.clear_messages()
        
        plan = await self.think(task)
        result = await self.act(plan)
        
        if result.success:
            observation = await self.observe(result)
            result.content = f"{result.content}\n\nğŸ“Š æ´å¯Ÿ: {observation}"
        
        return result
