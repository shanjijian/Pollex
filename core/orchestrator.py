"""
Orchestrator - ç¼–æ’å™¨
ä¸­å¤®æ™ºèƒ½ä½“ï¼Œè´Ÿè´£ä»»åŠ¡åˆ†è§£å’Œæ™ºèƒ½ä½“è°ƒåº¦
"""
import json
from typing import Dict, List, Optional
from openai import AsyncOpenAI
from dataclasses import dataclass

from core.agent import BaseAgent, AgentRole, AgentResponse, Message
from agents.code import CodeAgent
from agents.browser import BrowserAgent
from agents.file import FileAgent
from agents.data import DataAgent
from core.memory import Memory
from config import config
from utils.log import get_logger

logger = get_logger("core")


@dataclass
class TaskPlan:
    """ä»»åŠ¡è®¡åˆ’"""
    original_task: str
    subtasks: List[Dict]
    current_step: int = 0


ORCHESTRATOR_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡ç¼–æ’æ™ºèƒ½ä½“ï¼ˆOrchestratorï¼‰ã€‚ä½ è´Ÿè´£ï¼š
1. åˆ†æç”¨æˆ·çš„å¤æ‚ä»»åŠ¡
2. å°†ä»»åŠ¡åˆ†è§£ä¸ºå¯æ‰§è¡Œçš„å­ä»»åŠ¡
3. ä¸ºæ¯ä¸ªå­ä»»åŠ¡é€‰æ‹©åˆé€‚çš„ä¸“ä¸šæ™ºèƒ½ä½“
4. åè°ƒæ™ºèƒ½ä½“ä¹‹é—´çš„åä½œ
5. æ±‡æ€»ç»“æœè¿”å›ç»™ç”¨æˆ·

ä½ å¯ç”¨çš„ä¸“ä¸šæ™ºèƒ½ä½“ï¼š
- code: ä»£ç ç”Ÿæˆå’Œæ‰§è¡Œï¼ˆPythonï¼‰
- browser: ç½‘é¡µæœç´¢å’Œå†…å®¹è·å–
- file: æ–‡ä»¶è¯»å†™å’Œç›®å½•ç®¡ç†
- data: æ•°æ®åˆ†æå’Œå¯è§†åŒ–

ä½ éœ€è¦åˆ†æä»»åŠ¡ï¼Œç„¶åè°ƒç”¨ assign_task å·¥å…·æ¥åˆ†é…å­ä»»åŠ¡ã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼šå½“ä½ å†³å®šåˆ†é…ä»»åŠ¡æ—¶ï¼Œä½¿ç”¨ assign_task å·¥å…·ï¼Œå‚æ•°å¦‚ä¸‹ï¼š
- agent: é€‰æ‹©çš„æ™ºèƒ½ä½“ç±»å‹ï¼ˆcode/browser/file/dataï¼‰
- task: å…·ä½“çš„å­ä»»åŠ¡æè¿°
- reason: é€‰æ‹©è¯¥æ™ºèƒ½ä½“çš„åŸå› 

å¦‚æœä»»åŠ¡å¯ä»¥ç›´æ¥å›ç­”ä¸éœ€è¦è°ƒç”¨æ™ºèƒ½ä½“ï¼Œç›´æ¥å›å¤å³å¯ã€‚"""


class Orchestrator(BaseAgent):
    """
    ç¼–æ’å™¨ - å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ ¸å¿ƒ
    
    è´Ÿè´£ï¼š
    - ä»»åŠ¡åˆ†æå’Œåˆ†è§£
    - æ™ºèƒ½ä½“é€‰æ‹©å’Œè°ƒåº¦
    - ç»“æœæ±‡æ€»å’Œè¿­ä»£
    """
    
    def __init__(self):
        super().__init__(
            name="Orchestrator",
            role=AgentRole.ORCHESTRATOR,
            system_prompt=ORCHESTRATOR_PROMPT,
            tools=[]
        )
        
        # åˆå§‹åŒ–ä¸“ä¸šæ™ºèƒ½ä½“
        self.agents: Dict[str, BaseAgent] = {
            "code": CodeAgent(),
            "browser": BrowserAgent(),
            "file": FileAgent(),
            "data": DataAgent(),
        }
        
        # å†…å­˜ç³»ç»Ÿ
        self.memory = Memory()
        
        # å½“å‰ä»»åŠ¡è®¡åˆ’
        self.current_plan: Optional[TaskPlan] = None
        
        # OpenAI å®¢æˆ·ç«¯
        self.client: Optional[AsyncOpenAI] = None
    
    def _ensure_client(self):
        """ç¡®ä¿ OpenAI å®¢æˆ·ç«¯å·²åˆå§‹åŒ–"""
        if self.client is None:
            if config.llm_config is None:
                raise ValueError("è¯·å…ˆè°ƒç”¨ init_config() åˆå§‹åŒ–é…ç½®")
            self.client = AsyncOpenAI(api_key=config.llm_config.api_key, base_url=config.llm_config.base_url)
    
    def _get_tools_schema(self) -> List[Dict]:
        """è·å–ç¼–æ’å™¨å¯ç”¨çš„å·¥å…·"""
        return [{
            "type": "function",
            "function": {
                "name": "assign_task",
                "description": "å°†å­ä»»åŠ¡åˆ†é…ç»™ä¸“ä¸šæ™ºèƒ½ä½“æ‰§è¡Œ",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "agent": {
                            "type": "string",
                            "enum": ["code", "browser", "file", "data"],
                            "description": "é€‰æ‹©çš„æ™ºèƒ½ä½“ç±»å‹"
                        },
                        "task": {
                            "type": "string",
                            "description": "å…·ä½“çš„å­ä»»åŠ¡æè¿°"
                        },
                        "reason": {
                            "type": "string",
                            "description": "é€‰æ‹©è¯¥æ™ºèƒ½ä½“çš„åŸå› "
                        }
                    },
                    "required": ["agent", "task", "reason"]
                }
            }
        }]
    
    async def think(self, task: str) -> str:
        """
        åˆ†æä»»åŠ¡ï¼Œåˆ¶å®šæ‰§è¡Œè®¡åˆ’
        """
        logger.info("\nğŸ¤– [ORCHESTRATOR] æ€è€ƒä¸­...")
        self._ensure_client()
        
        # æ·»åŠ ä¸Šä¸‹æ–‡
        context = self.memory.get_context(limit=5)
        if context:
            enhanced_task = f"ä¸Šä¸‹æ–‡:\n{context}\n\nå½“å‰ä»»åŠ¡: {task}"
            logger.info(f"   æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯")
            logger.info(f"   ä¸Šä¸‹æ–‡å†…å®¹: {context}")
        else:
            enhanced_task = task
        
        self.add_message(Message(role="user", content=enhanced_task))
        
        response = await self.client.chat.completions.create(
            model=config.llm_config.model,
            messages=self.get_messages_for_llm(),
            tools=self._get_tools_schema(),
            temperature=config.llm_config.temperature,
        )
        message = response.choices[0].message
        
        self.add_message(Message(
            role="assistant",
            content=message.content or "",
            tool_calls=[tc.model_dump() for tc in message.tool_calls] if message.tool_calls else None
        ))
        
        # ä¿å­˜åˆ°è®°å¿†
        self.memory.add_short_term(f"ä»»åŠ¡: {task}", type="task")
        
        if message.tool_calls:
            subtasks = []
            for tc in message.tool_calls:
                func = tc.function
                args = json.loads(func.arguments)
                subtasks.append({
                    "id": tc.id,
                    "agent": args["agent"],
                    "task": args["task"],
                    "reason": args["reason"]
                })
            
            self.current_plan = TaskPlan(
                original_task=task,
                subtasks=subtasks
            )
            logger.info(f"   ç”Ÿæˆ {len(subtasks)} ä¸ªå­ä»»åŠ¡")
            logger.info(f"   å­ä»»åŠ¡è¯¦æƒ…: {subtasks}")
            return f"è®¡åˆ’æ‰§è¡Œ {len(subtasks)} ä¸ªå­ä»»åŠ¡"
        
        return message.content or "æ— éœ€æ‰§è¡Œå­ä»»åŠ¡"
    
    async def act(self, plan: str) -> AgentResponse:
        """
        æ‰§è¡Œè®¡åˆ’ï¼šè°ƒç”¨ä¸“ä¸šæ™ºèƒ½ä½“å®Œæˆå­ä»»åŠ¡
        """
        if not self.current_plan or not self.current_plan.subtasks:
            # æ²¡æœ‰å­ä»»åŠ¡ï¼Œç›´æ¥è¿”å› LLM çš„å›å¤
            if self.messages:
                return AgentResponse(
                    success=True,
                    content=self.messages[-1].content,
                    data=None
                )
            return AgentResponse(success=False, content="", error="æ²¡æœ‰æ‰§è¡Œè®¡åˆ’")
        
        results = []
        logger.info("\nğŸ¤– [ORCHESTRATOR] æ‰§è¡Œå­ä»»åŠ¡...")
        for i, subtask in enumerate(self.current_plan.subtasks, 1):
            agent_type = subtask["agent"]
            task_desc = subtask["task"]
            logger.debug(f"æ‰§è¡Œå­ä»»åŠ¡ {i}/{len(self.current_plan.subtasks)}: {agent_type} - {task_desc[:50]}...")
            
            if config.system_config.verbose:
                logger.info(f"\nğŸ¤– [{agent_type.upper()}] æ‰§è¡Œ: {task_desc[:50]}...")
            
            # è·å–å¯¹åº”çš„æ™ºèƒ½ä½“å¹¶æ‰§è¡Œ
            agent = self.agents.get(agent_type)
            if agent:
                try:
                    logger.debug(f"è°ƒç”¨æ™ºèƒ½ä½“ {agent_type}")
                    result = await agent.run(task_desc)
                    logger.debug(f"æ™ºèƒ½ä½“ {agent_type} æ‰§è¡Œå®Œæˆï¼Œç»“æœé•¿åº¦: {len(result.content)}")
                    results.append({
                        "agent": agent_type,
                        "task": task_desc,
                        "success": result.success,
                        "output": result.content
                    })
                    
                    # æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
                    self.add_message(Message(
                        role="tool",
                        content=f"[{agent_type}] {result.content[:1000]}",
                        tool_call_id=subtask["id"]
                    ))
                    
                except Exception as e:
                    logger.error(f"æ™ºèƒ½ä½“ {agent_type} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
                    results.append({
                        "agent": agent_type,
                        "task": task_desc,
                        "success": False,
                        "error": str(e)
                    })
            else:
                logger.warning(f"æœªæ‰¾åˆ°æ™ºèƒ½ä½“: {agent_type}")
                results.append({
                    "agent": agent_type,
                    "task": task_desc,
                    "success": False,
                    "error": f"æœªæ‰¾åˆ°æ™ºèƒ½ä½“ {agent_type}"
                })
        
        # æ±‡æ€»ç»“æœ
        all_success = all(r.get("success", False) for r in results)
        logger.info(f"å­ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼ŒæˆåŠŸç‡: {sum(1 for r in results if r.get('success'))}/{len(results)}")
        
        output_parts = []
        for r in results:
            status = "âœ…" if r.get("success") else "âŒ"
            output_parts.append(f"{status} [{r['agent']}] {r['task']}\n{r.get('output', r.get('error', ''))}")
        
        content = "\n\n---\n\n".join(output_parts)
        logger.info(f"å­ä»»åŠ¡ç»“æœæ±‡æ€»:\n{content[:1000]}...")
        return AgentResponse(
            success=all_success,
            content=content,
            data=results
        )
    
    async def observe(self, result: AgentResponse) -> str:
        """
        è§‚å¯Ÿæ‰§è¡Œç»“æœï¼Œç”Ÿæˆæœ€ç»ˆæ€»ç»“
        """
        self._ensure_client()
        
        # ä¿å­˜ç»“æœåˆ°è®°å¿†
        self.memory.add_short_term(
            f"æ‰§è¡Œç»“æœ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}",
            type="result"
        )
        
        # è®© LLM ç”Ÿæˆæœ€ç»ˆæ€»ç»“
        self.add_message(Message(
            role="user",
            content=f"è¯·æ ¹æ®ä»¥ä¸Šæ‰§è¡Œç»“æœï¼Œç»™ç”¨æˆ·ä¸€ä¸ªç®€æ´æ¸…æ™°çš„æœ€ç»ˆå›å¤ã€‚åŒ…æ‹¬ï¼š\n1. å®Œæˆäº†ä»€ä¹ˆ\n2. å…³é”®ç»“æœ\n3. éœ€è¦æ³¨æ„çš„äº‹é¡¹ï¼ˆå¦‚æœæœ‰ï¼‰"
        ))
        
        response = await self.client.chat.completions.create(
            model=config.llm_config.model,
            messages=self.get_messages_for_llm(),
            temperature=0.3,
            max_tokens=1000
        )
        
        summary = response.choices[0].message.content
        self.add_message(Message(role="assistant", content=summary))
        
        # ä¿å­˜åˆ°é•¿æœŸè®°å¿†
        if self.current_plan:
            self.memory.add_long_term(
                f"ä»»åŠ¡: {self.current_plan.original_task}\nç»“æœ: {summary[:500]}",
                type="observation",
                importance=0.7
            )
        logger.info(f"\nğŸ¤– [ORCHESTRATOR] è§‚å¯Ÿæ€»ç»“:\n{summary[:1000]}...")
        return summary
    
    async def run(self, task: str) -> AgentResponse:
        """
        è¿è¡Œå®Œæ•´çš„ä»»åŠ¡ç¼–æ’æµç¨‹
        
        Args:
            task: ç”¨æˆ·ä»»åŠ¡æè¿°
            
        Returns:
            AgentResponse: æœ€ç»ˆç»“æœ
        """
        self.clear_messages()
        self.current_plan = None
        if config.system_config.verbose:
            logger.info(f"\nğŸ“‹ æ”¶åˆ°ä»»åŠ¡: {task}")
            logger.info("=" * 50)
        
        # è¿­ä»£æ‰§è¡Œå¾ªç¯
        for iteration in range(config.system_config.max_iterations):
            if config.system_config.verbose:
                logger.info(f"\nğŸ”„ è¿­ä»£ {iteration + 1}")
            
            # Think
            plan = await self.think(task)
            if config.system_config.verbose:
                logger.info(f"   æ€è€ƒ: {plan}")
            
            # Act
            result = await self.act(plan)
            if config.system_config.verbose:
                logger.info(f"   æ‰§è¡Œ: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}")
            
            # Observe
            observation = await self.observe(result)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­è¿­ä»£
            if result.success or not self.current_plan:
                break
            
            # å‡†å¤‡ä¸‹ä¸€è½®è¿­ä»£
            task = f"ä¸Šä¸€æ­¥ç»“æœ:\n{observation}\n\nè¯·ç»§ç»­å®ŒæˆåŸå§‹ä»»åŠ¡æˆ–å¤„ç†é‡åˆ°çš„é—®é¢˜ã€‚"
        
        if config.system_config.verbose:
            logger.info("\n" + "=" * 50)
            logger.info("âœ… ä»»åŠ¡å®Œæˆ")
        
        return AgentResponse(
            success=result.success,
            content=observation,
            data=result.data
        )
    
    def get_status(self) -> str:
        """è·å–ç¼–æ’å™¨çŠ¶æ€"""
        status = f"ç¼–æ’å™¨çŠ¶æ€:\n"
        status += f"  - å¯ç”¨æ™ºèƒ½ä½“: {', '.join(self.agents.keys())}\n"
        status += f"  - {self.memory.summarize()}\n"
        if self.current_plan:
            status += f"  - å½“å‰è®¡åˆ’: {len(self.current_plan.subtasks)} ä¸ªå­ä»»åŠ¡\n"
        return status
